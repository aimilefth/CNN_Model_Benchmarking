{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Common Includes","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nprint(\"TF version:\", tf.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n!lscpu | grep 'Model name'\n!lscpu | grep 'Socket(s):'\n!lscpu | grep 'Core(s) per socket'\n!lscpu | grep 'Thread(s) per core'\n!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nBATCH_SIZE = 32\n\nds_train = tf.keras.utils.image_dataset_from_directory(\n    directory = \"../input/imagenetmini-1000/imagenet-mini/train\",\n    labels = \"inferred\",\n    label_mode = \"int\",\n    color_mode = \"rgb\",\n    batch_size = BATCH_SIZE,\n    image_size = (299, 299),\n)\n\nds_val = tf.keras.utils.image_dataset_from_directory(\n    directory = \"../input/imagenetmini-1000/imagenet-mini/val\",\n    labels = \"inferred\",\n    label_mode = \"int\",\n    color_mode = \"rgb\",\n    batch_size = BATCH_SIZE,\n    image_size = (299, 299)\n)\n\ndef normalize_image(image, label):\n    #image = tf.keras.applications.resnet.preprocess_input(image)\n    image = tf.cast(x=image, dtype=tf.float32)/127.5 - 1.0\n    return image, label\n\n#ds_train = ds_train.shuffle(100)\nds_train = ds_train.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\n#ds_train = ds_train.cache()\n#ds_train = ds_train.prefetch(buffer_size=AUTOTUNE)\n\nds_val = ds_val.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\nds_val = ds_val.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T14:22:59.733398Z","iopub.execute_input":"2022-05-30T14:22:59.733676Z","iopub.status.idle":"2022-05-30T14:23:02.953400Z","shell.execute_reply.started":"2022-05-30T14:22:59.733645Z","shell.execute_reply":"2022-05-30T14:23:02.952653Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Found 34745 files belonging to 1000 classes.\nFound 3923 files belonging to 1000 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Model ResNet152 with 299,299,3 input size","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE = (299,299,3)\n\nmodel = tf.keras.applications.resnet.ResNet152(\n    include_top=True,\n    weights=None,\n    input_tensor=None,\n    input_shape=INPUT_SHAPE,\n    classes=1000,\n    classifier_activation=None,\n)\n\n\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom keras.models import Model\n\ndef insert_layer_nonseq(model, layer_regex, insert_layer_factory,\n                        insert_layer_name=None, position='after'):\n\n    # Auxiliary dictionary to describe the network graph\n    network_dict = {'input_layers_of': {}, 'new_output_tensor_of': {}}\n\n    # Set the input layers of each layer\n    for layer in model.layers:\n        for node in layer._outbound_nodes:\n            layer_name = node.outbound_layer.name\n            if layer_name not in network_dict['input_layers_of']:\n                network_dict['input_layers_of'].update(\n                        {layer_name: [layer.name]})\n            else:\n                network_dict['input_layers_of'][layer_name].append(layer.name)\n\n    # Set the output tensor of the input layer\n    network_dict['new_output_tensor_of'].update(\n            {model.layers[0].name: model.input})\n\n    # Iterate over all layers after the input\n    model_outputs = []\n    for layer in model.layers[1:]:\n\n        # Determine input tensors\n        layer_input = [network_dict['new_output_tensor_of'][layer_aux] \n                for layer_aux in network_dict['input_layers_of'][layer.name]]\n        if len(layer_input) == 1:\n            layer_input = layer_input[0]\n\n        # Insert layer if name matches the regular expression\n        if re.match(layer_regex, layer.name):\n            if position == 'replace':\n                x = layer_input\n            elif position == 'after':\n                x = layer(layer_input)\n            elif position == 'before':\n                pass\n            else:\n                raise ValueError('position must be: before, after or replace')\n\n            new_layer = insert_layer_factory()\n            #f insert_layer_name:\n            #   new_layer.name = insert_layer_name\n            #lse:\n            #   new_layer.name = '{}_{}'.format(layer.name, \n            #                                 new_layer.name)\n            x = new_layer(x)\n            print('New layer: {} Old layer: {} Type: {}'.format(new_layer.name,\n                                                            layer.name, position))\n            if position == 'before':\n                x = layer(x)\n        else:\n            x = layer(layer_input)\n\n        # Set new output tensor (the original one, or the one of the inserted\n        # layer)\n        network_dict['new_output_tensor_of'].update({layer.name: x})\n\n        # Save tensor in output list if it is output in initial model\n        if layer.name in model.output_names:\n            model_outputs.append(x)\n            print(x)\n            print(model.output_names)\n    return Model(inputs=model.inputs, outputs=model_outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Avg_pool_2_factory():\n    return tf.keras.layers.AveragePooling2D(pool_size=(2, 2), name=\"avg_pool_2\")\n\ndef Global_avg_pool_factory():\n    return tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool_5\")\n\nmodel = insert_layer_nonseq(model=model, layer_regex='avg_pool', insert_layer_factory=Avg_pool_2_factory,\n                       position='replace')\nmodel.save(\"./temp1\")\nmodel = keras.models.load_model(\"./temp1\")\nmodel = insert_layer_nonseq(model=model, layer_regex='avg_pool_2', insert_layer_factory=Global_avg_pool_factory,\n                       position='after')\n\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n)                                            \nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluate","metadata":{}},{"cell_type":"code","source":"model.evaluate(ds_val, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:34:37.111927Z","iopub.execute_input":"2022-05-30T22:34:37.112271Z","iopub.status.idle":"2022-05-30T22:35:18.183866Z","shell.execute_reply.started":"2022-05-30T22:34:37.112235Z","shell.execute_reply":"2022-05-30T22:35:18.183085Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"123/123 [==============================] - 32s 246ms/step - loss: 9.5805 - accuracy: 2.5491e-04 - sparse_top_k_categorical_accuracy: 0.2027\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[9.580506324768066, 0.0002549069467931986, 0.2026510387659073]"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint_filepath = 'best_ResNet152_trick.h5'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='\"val_sparse_top_k_categorical_accuracy\"',\n    mode='max',\n    save_best_only=True)\nmodel.fit(ds_train, validation_data=ds_val, verbose=1, epochs=50, callbacks=[model_checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2022-05-30T14:23:12.569499Z","iopub.execute_input":"2022-05-30T14:23:12.569763Z","iopub.status.idle":"2022-05-30T22:30:34.376132Z","shell.execute_reply.started":"2022-05-30T14:23:12.569733Z","shell.execute_reply":"2022-05-30T22:30:34.374085Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1086/1086 [==============================] - 809s 742ms/step - loss: 6.9148 - accuracy: 0.0000e+00 - sparse_top_k_categorical_accuracy: 0.0140 - val_loss: 7.6273 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0092\nEpoch 2/50\n1086/1086 [==============================] - 810s 744ms/step - loss: 6.6829 - accuracy: 0.0000e+00 - sparse_top_k_categorical_accuracy: 0.0211 - val_loss: 7.4928 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0171\nEpoch 3/50\n1086/1086 [==============================] - 809s 744ms/step - loss: 6.5258 - accuracy: 0.0000e+00 - sparse_top_k_categorical_accuracy: 0.0287 - val_loss: 6.8024 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0191\nEpoch 4/50\n1086/1086 [==============================] - 809s 744ms/step - loss: 6.4177 - accuracy: 2.8781e-05 - sparse_top_k_categorical_accuracy: 0.0333 - val_loss: 7.0978 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0257\nEpoch 5/50\n1086/1086 [==============================] - 806s 741ms/step - loss: 6.2984 - accuracy: 3.4537e-04 - sparse_top_k_categorical_accuracy: 0.0425 - val_loss: 6.9494 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0278\nEpoch 6/50\n1086/1086 [==============================] - 810s 745ms/step - loss: 6.1451 - accuracy: 0.0000e+00 - sparse_top_k_categorical_accuracy: 0.0556 - val_loss: 6.4547 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0433\nEpoch 7/50\n1086/1086 [==============================] - 809s 744ms/step - loss: 5.9993 - accuracy: 3.7415e-04 - sparse_top_k_categorical_accuracy: 0.0677 - val_loss: 11.0979 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0495\nEpoch 8/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 5.8096 - accuracy: 3.1659e-04 - sparse_top_k_categorical_accuracy: 0.0893 - val_loss: 6.6546 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0630\nEpoch 9/50\n1086/1086 [==============================] - 812s 747ms/step - loss: 5.5979 - accuracy: 2.8781e-04 - sparse_top_k_categorical_accuracy: 0.1157 - val_loss: 6.1590 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0811\nEpoch 10/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 5.3946 - accuracy: 6.9075e-04 - sparse_top_k_categorical_accuracy: 0.1461 - val_loss: 6.0866 - val_accuracy: 2.5491e-04 - val_sparse_top_k_categorical_accuracy: 0.0874\nEpoch 11/50\n1086/1086 [==============================] - 807s 742ms/step - loss: 5.1914 - accuracy: 0.0011 - sparse_top_k_categorical_accuracy: 0.1783 - val_loss: 6.0035 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.1134\nEpoch 12/50\n1086/1086 [==============================] - 807s 742ms/step - loss: 4.9839 - accuracy: 8.6343e-04 - sparse_top_k_categorical_accuracy: 0.2101 - val_loss: 6.4099 - val_accuracy: 5.0981e-04 - val_sparse_top_k_categorical_accuracy: 0.1331\nEpoch 13/50\n1086/1086 [==============================] - 822s 757ms/step - loss: 4.7456 - accuracy: 0.0012 - sparse_top_k_categorical_accuracy: 0.2565 - val_loss: 5.7923 - val_accuracy: 5.0981e-04 - val_sparse_top_k_categorical_accuracy: 0.1517\nEpoch 14/50\n1086/1086 [==============================] - 808s 743ms/step - loss: 4.4977 - accuracy: 0.0014 - sparse_top_k_categorical_accuracy: 0.3019 - val_loss: 6.2900 - val_accuracy: 0.0010 - val_sparse_top_k_categorical_accuracy: 0.1366\nEpoch 15/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 4.2765 - accuracy: 0.0018 - sparse_top_k_categorical_accuracy: 0.3428 - val_loss: 6.6122 - val_accuracy: 0.0018 - val_sparse_top_k_categorical_accuracy: 0.1619\nEpoch 16/50\n1086/1086 [==============================] - 809s 745ms/step - loss: 4.0261 - accuracy: 0.0018 - sparse_top_k_categorical_accuracy: 0.3956 - val_loss: 7.3297 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.0981\nEpoch 17/50\n1086/1086 [==============================] - 810s 745ms/step - loss: 3.8306 - accuracy: 0.0016 - sparse_top_k_categorical_accuracy: 0.4330 - val_loss: 6.0873 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.1672\nEpoch 18/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 3.5226 - accuracy: 0.0012 - sparse_top_k_categorical_accuracy: 0.4951 - val_loss: 8.9316 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.1723\nEpoch 19/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 3.2394 - accuracy: 0.0014 - sparse_top_k_categorical_accuracy: 0.5496 - val_loss: 8.9742 - val_accuracy: 7.6472e-04 - val_sparse_top_k_categorical_accuracy: 0.1868\nEpoch 20/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 2.8794 - accuracy: 0.0012 - sparse_top_k_categorical_accuracy: 0.6201 - val_loss: 8.0775 - val_accuracy: 0.0010 - val_sparse_top_k_categorical_accuracy: 0.1787\nEpoch 21/50\n1086/1086 [==============================] - 809s 744ms/step - loss: 2.5530 - accuracy: 0.0013 - sparse_top_k_categorical_accuracy: 0.6829 - val_loss: 9.6389 - val_accuracy: 0.0013 - val_sparse_top_k_categorical_accuracy: 0.1919\nEpoch 22/50\n1086/1086 [==============================] - 808s 743ms/step - loss: 2.1976 - accuracy: 0.0013 - sparse_top_k_categorical_accuracy: 0.7474 - val_loss: 12.5508 - val_accuracy: 0.0010 - val_sparse_top_k_categorical_accuracy: 0.1746\nEpoch 23/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 1.8595 - accuracy: 0.0012 - sparse_top_k_categorical_accuracy: 0.8076 - val_loss: 10.5964 - val_accuracy: 0.0013 - val_sparse_top_k_categorical_accuracy: 0.1917\nEpoch 24/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 1.5654 - accuracy: 9.2100e-04 - sparse_top_k_categorical_accuracy: 0.8550 - val_loss: 9.6602 - val_accuracy: 0.0010 - val_sparse_top_k_categorical_accuracy: 0.1550\nEpoch 25/50\n1086/1086 [==============================] - 822s 756ms/step - loss: 1.2239 - accuracy: 0.0011 - sparse_top_k_categorical_accuracy: 0.9051 - val_loss: 9.6416 - val_accuracy: 0.0000e+00 - val_sparse_top_k_categorical_accuracy: 0.1876\nEpoch 26/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 0.9607 - accuracy: 9.2100e-04 - sparse_top_k_categorical_accuracy: 0.9381 - val_loss: 10.2048 - val_accuracy: 5.0981e-04 - val_sparse_top_k_categorical_accuracy: 0.1800\nEpoch 27/50\n1086/1086 [==============================] - 811s 746ms/step - loss: 0.7484 - accuracy: 9.2100e-04 - sparse_top_k_categorical_accuracy: 0.9637 - val_loss: 15.2364 - val_accuracy: 2.5491e-04 - val_sparse_top_k_categorical_accuracy: 0.1838\nEpoch 28/50\n1086/1086 [==============================] - 806s 742ms/step - loss: 0.6013 - accuracy: 8.3465e-04 - sparse_top_k_categorical_accuracy: 0.9772 - val_loss: 11.7836 - val_accuracy: 7.6472e-04 - val_sparse_top_k_categorical_accuracy: 0.1909\nEpoch 29/50\n1086/1086 [==============================] - 806s 742ms/step - loss: 0.4842 - accuracy: 9.7856e-04 - sparse_top_k_categorical_accuracy: 0.9853 - val_loss: 10.7766 - val_accuracy: 0.0036 - val_sparse_top_k_categorical_accuracy: 0.1769\nEpoch 30/50\n1086/1086 [==============================] - 806s 741ms/step - loss: 0.4392 - accuracy: 9.7856e-04 - sparse_top_k_categorical_accuracy: 0.9878 - val_loss: 11.5388 - val_accuracy: 7.6472e-04 - val_sparse_top_k_categorical_accuracy: 0.1909\nEpoch 31/50\n1086/1086 [==============================] - 819s 753ms/step - loss: 0.3448 - accuracy: 0.0011 - sparse_top_k_categorical_accuracy: 0.9925 - val_loss: 14.1854 - val_accuracy: 2.5491e-04 - val_sparse_top_k_categorical_accuracy: 0.1904\nEpoch 32/50\n1086/1086 [==============================] - 810s 745ms/step - loss: 0.3595 - accuracy: 9.2100e-04 - sparse_top_k_categorical_accuracy: 0.9907 - val_loss: 11.9581 - val_accuracy: 0.0013 - val_sparse_top_k_categorical_accuracy: 0.1858\nEpoch 33/50\n1086/1086 [==============================] - 810s 745ms/step - loss: 0.2985 - accuracy: 9.2100e-04 - sparse_top_k_categorical_accuracy: 0.9943 - val_loss: 14.5346 - val_accuracy: 0.0015 - val_sparse_top_k_categorical_accuracy: 0.1991\nEpoch 34/50\n1086/1086 [==============================] - 809s 744ms/step - loss: 0.2625 - accuracy: 0.0010 - sparse_top_k_categorical_accuracy: 0.9953 - val_loss: 11.3974 - val_accuracy: 0.0010 - val_sparse_top_k_categorical_accuracy: 0.1736\nEpoch 35/50\n 877/1086 [=======================>......] - ETA: 2:30 - loss: 0.2672 - accuracy: 9.6209e-04 - sparse_top_k_categorical_accuracy: 0.9947","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/387185548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     save_best_only=True)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"Calculate Flops","metadata":{}},{"cell_type":"code","source":"!pip install keras-flops\nfrom keras_flops import get_flops\nflops = get_flops(model, batch_size=1)\nprint(f\"FLOPS: {flops / 10 ** 9:.03} G\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save Model","metadata":{}},{"cell_type":"code","source":"Model_Name = \"ResNet152_trick_35ep_41_9GF\"\nos.environ[\"MODELNAME\"] = Model_Name\nos.environ[\"MODELNAMEZIP\"] = Model_Name + \".zip\"\nmodel.save(\"./\" + Model_Name)\n!zip -r ./$MODELNAMEZIP ./$MODELNAME\n!rm -rf ./$MODELNAME","metadata":{"execution":{"iopub.status.busy":"2022-05-30T22:30:55.296309Z","iopub.execute_input":"2022-05-30T22:30:55.297692Z","iopub.status.idle":"2022-05-30T22:33:28.275594Z","shell.execute_reply.started":"2022-05-30T22:30:55.297651Z","shell.execute_reply":"2022-05-30T22:33:28.274523Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"  adding: ResNet152_trick_35ep_41_9GF/ (stored 0%)\n  adding: ResNet152_trick_35ep_41_9GF/saved_model.pb (deflated 93%)\n  adding: ResNet152_trick_35ep_41_9GF/keras_metadata.pb (deflated 96%)\n  adding: ResNet152_trick_35ep_41_9GF/variables/ (stored 0%)\n  adding: ResNet152_trick_35ep_41_9GF/variables/variables.data-00000-of-00001 (deflated 7%)\n  adding: ResNet152_trick_35ep_41_9GF/variables/variables.index (deflated 83%)\n  adding: ResNet152_trick_35ep_41_9GF/assets/ (stored 0%)\n","output_type":"stream"}]}]}