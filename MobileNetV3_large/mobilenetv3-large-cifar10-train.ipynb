{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T16:36:47.737670Z","iopub.execute_input":"2022-04-12T16:36:47.738153Z","iopub.status.idle":"2022-04-12T16:36:47.744564Z","shell.execute_reply.started":"2022-04-12T16:36:47.738113Z","shell.execute_reply":"2022-04-12T16:36:47.743629Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Common Includes","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\nimport tensorflow_datasets as tfds\nprint(\"TF version:\", tf.__version__)\nprint(\"Hub version:\", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n!lscpu |grep 'Model name'\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:29:12.028373Z","iopub.execute_input":"2022-04-12T16:29:12.029017Z","iopub.status.idle":"2022-04-12T16:29:20.275051Z","shell.execute_reply.started":"2022-04-12T16:29:12.028922Z","shell.execute_reply":"2022-04-12T16:29:20.273935Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Importing the cifar10 dataset and creating an input pipeline\n\nDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB)","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nBATCH_SIZE = 64\nBUFFER_SIZE = 1000\nPERCENTAGE_GRAYSCALE = 0.1\nMAX_BRIGHT_DELTA = 0.1\n\n(ds_train, ds_test), ds_info = tfds.load(\n    name=\"cifar10\",\n    split=[\"train\", \"test\"],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\nprint(ds_info)\nfig = tfds.show_examples(ds_train, ds_info, rows=4, cols=4)\n\ndef normalize_image(image, label):\n    return tf.cast(x=image, dtype=tf.float32)/255.0, label\ndef resize_image(image, label):\n    new_height = new_width = 224\n    image = tf.image.resize(image, (new_height,new_width))\n    return image, label\ndef augment(image, label):\n    if(tf.random.uniform(shape=(), minval=0.0, maxval=1.0) < PERCENTAGE_GRAYSCALE):\n        image = tf.tile(tf.image.rgb_to_grayscale(image), [1, 1, 3])\n    image = tf.image.random_brightness(image, max_delta=MAX_BRIGHT_DELTA)\n    #image = tf.image.random_contrast(image, lower=CONTRAST_LOWER, upper=CONTRAST_UPPER) #bad\n    \n    image = tf.image.random_flip_left_right(image) #50%\n    return image, label\n\nds_train = ds_train.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\nds_train = ds_train.map(map_func=augment, num_parallel_calls=AUTOTUNE)\nds_train = ds_train.shuffle(buffer_size=BUFFER_SIZE)\nds_train = ds_train.batch(batch_size=BATCH_SIZE)\nds_train = ds_train.prefetch(buffer_size=AUTOTUNE)\nds_train = ds_train.map(map_func=resize_image, num_parallel_calls=AUTOTUNE) #This goes last to reduce the memory footprint\n\nds_test = ds_test.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\nds_test = ds_test.batch(batch_size=BATCH_SIZE)\nds_test = ds_test.prefetch(buffer_size=AUTOTUNE)\nds_test = ds_test.map(map_func=resize_image, num_parallel_calls=AUTOTUNE)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:29:23.931853Z","iopub.execute_input":"2022-04-12T16:29:23.932309Z","iopub.status.idle":"2022-04-12T16:30:31.228222Z","shell.execute_reply.started":"2022-04-12T16:29:23.932267Z","shell.execute_reply":"2022-04-12T16:30:31.227513Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Creating the cifar10 model, as well as the MobileNet for imagenet, and getting the summaries","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE = (224,224,3)\nDROPOUT_RATE = 0.1\nREGULARIZING_FACTOR = 0.0001\nLEARNING_RATE = 0.001\n\n\nmodel = keras.Sequential([\n    layers.Input(shape=INPUT_SHAPE),\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\", trainable=False),\n    tf.keras.layers.Dropout(rate=DROPOUT_RATE),\n    layers.Dense(units=10, kernel_regularizer=keras.regularizers.l2(REGULARIZING_FACTOR))\n])\n\nEPOCHS = 5\n\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nmodel_full = keras.Sequential([\n    layers.Input(shape=INPUT_SHAPE),\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\", trainable=False),\n])\n\nmodel_full.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:30:41.116546Z","iopub.execute_input":"2022-04-12T16:30:41.117195Z","iopub.status.idle":"2022-04-12T16:30:45.272759Z","shell.execute_reply.started":"2022-04-12T16:30:41.117149Z","shell.execute_reply":"2022-04-12T16:30:45.271893Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Calculating the FLOPs of the models","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n\ndef get_flops(model):\n    concrete = tf.function(lambda inputs: model(inputs))\n    concrete_func = concrete.get_concrete_function(\n        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n    with tf.Graph().as_default() as graph:\n        tf.graph_util.import_graph_def(graph_def, name='')\n        run_meta = tf.compat.v1.RunMetadata()\n        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n        return flops.total_float_ops\n    \n# The //2 is necessary since `profile` counts multiply and accumulate\n# as two flops, here we report the total number of multiply accumulate ops    \nprint(\"The FLOPs is:{}\".format(get_flops(model)//2) ,flush=True)\nprint(\"The FLOPs is:{}\".format(get_flops(model_full)//2) ,flush=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:31:06.788930Z","iopub.execute_input":"2022-04-12T16:31:06.789233Z","iopub.status.idle":"2022-04-12T16:31:11.804820Z","shell.execute_reply.started":"2022-04-12T16:31:06.789184Z","shell.execute_reply":"2022-04-12T16:31:11.804088Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Training the model (60s per Epoch)","metadata":{}},{"cell_type":"code","source":"model.fit(ds_train, epochs=EPOCHS, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:31:21.007468Z","iopub.execute_input":"2022-04-12T16:31:21.008242Z","iopub.status.idle":"2022-04-12T16:35:44.553030Z","shell.execute_reply.started":"2022-04-12T16:31:21.008169Z","shell.execute_reply":"2022-04-12T16:35:44.552341Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the Model","metadata":{}},{"cell_type":"code","source":"model.evaluate(ds_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:35:46.874565Z","iopub.execute_input":"2022-04-12T16:35:46.874822Z","iopub.status.idle":"2022-04-12T16:35:56.234739Z","shell.execute_reply.started":"2022-04-12T16:35:46.874792Z","shell.execute_reply":"2022-04-12T16:35:56.233445Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Evaluate the model with batch_size=1, to get the single batch average (1/100) inference time, on cpu","metadata":{}},{"cell_type":"code","source":"(ds_test_single), ds_info = tfds.load(\n    name=\"cifar10\",\n    split=\"test[0:100]\",\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\n\nds_test_single = ds_test_single.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\nds_test_single = ds_test_single.batch(batch_size=1)\nds_test_single = ds_test_single.prefetch(buffer_size=AUTOTUNE)\nds_test_single = ds_test_single.map(map_func=resize_image, num_parallel_calls=AUTOTUNE)\n\nwith tf.device('/cpu:0'):\n    model.evaluate(ds_test_single, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:36:21.828897Z","iopub.execute_input":"2022-04-12T16:36:21.829703Z","iopub.status.idle":"2022-04-12T16:36:25.628555Z","shell.execute_reply.started":"2022-04-12T16:36:21.829652Z","shell.execute_reply":"2022-04-12T16:36:25.627833Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Save the model, zip it and remove the folder to save space","metadata":{}},{"cell_type":"code","source":"Model_Name = \"MobileNetV3_large_Cifar10_90pct_0_22GF\"\nos.environ[\"MODELNAME\"] = Model_Name\nos.environ[\"MODELNAMEZIP\"] = Model_Name + \".zip\"\nmodel.save(\"./\" + Model_Name)\n!zip -r ./$MODELNAMEZIP ./$MODELNAME\n!rm -rf ./$MODELNAME","metadata":{"execution":{"iopub.status.busy":"2022-04-12T16:36:54.518767Z","iopub.execute_input":"2022-04-12T16:36:54.519028Z","iopub.status.idle":"2022-04-12T16:37:02.251688Z","shell.execute_reply.started":"2022-04-12T16:36:54.518997Z","shell.execute_reply":"2022-04-12T16:37:02.250284Z"},"trusted":true},"execution_count":14,"outputs":[]}]}