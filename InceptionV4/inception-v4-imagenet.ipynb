{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nprint(\"TF version:\", tf.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n!lscpu | grep 'Model name'\n!lscpu | grep 'Socket(s):'\n!lscpu | grep 'Core(s) per socket'\n!lscpu | grep 'Thread(s) per core'\n!nvidia-smi\n\nimport numpy as np\nimport tensorflow as tf\nimport warnings\n\nfrom keras.layers import Input, Dropout, Dense, Flatten, Activation, MaxPooling2D, Conv2D, AveragePooling2D, BatchNormalization, concatenate\nfrom keras.initializers import he_normal\nfrom keras.regularizers import l2\nfrom keras.models import Model\n\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:58:28.548912Z","iopub.execute_input":"2022-05-29T18:58:28.549604Z","iopub.status.idle":"2022-05-29T18:58:37.448655Z","shell.execute_reply.started":"2022-05-29T18:58:28.549496Z","shell.execute_reply":"2022-05-29T18:58:37.447682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nBATCH_SIZE = 64\n\nds_train = tf.keras.utils.image_dataset_from_directory(\n    directory = \"../input/imagenetmini-1000/imagenet-mini/train\",\n    labels = \"inferred\",\n    label_mode = \"int\",\n    color_mode = \"rgb\",\n    batch_size = BATCH_SIZE,\n    image_size = (299, 299),\n)\n\nds_val = tf.keras.utils.image_dataset_from_directory(\n    directory = \"../input/imagenetmini-1000/imagenet-mini/val\",\n    labels = \"inferred\",\n    label_mode = \"int\",\n    color_mode = \"rgb\",\n    batch_size = BATCH_SIZE,\n    image_size = (299, 299)\n)\n\ndef normalize_image(image, label):\n    #image = tf.keras.applications.resnet.preprocess_input(image)\n    image = tf.cast(x=image, dtype=tf.float32)/127.5 - 1.0\n    return image, label\n\n#ds_train = ds_train.shuffle(100)\nds_train = ds_train.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\n#ds_train = ds_train.cache()\n#ds_train = ds_train.prefetch(buffer_size=AUTOTUNE)\n\nds_val = ds_val.map(map_func=normalize_image, num_parallel_calls=AUTOTUNE)\nds_val = ds_val.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:58:44.958622Z","iopub.execute_input":"2022-05-29T18:58:44.959346Z","iopub.status.idle":"2022-05-29T18:58:47.385854Z","shell.execute_reply.started":"2022-05-29T18:58:44.959307Z","shell.execute_reply":"2022-05-29T18:58:47.384848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inception Modules","metadata":{}},{"cell_type":"code","source":"def conv_bn(x, filters, kernel_size, strides, padding='same', use_bias=False):\n    # Define the joint function to apply the combination of Conv and BatchNorm \n    x = Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias,\n               kernel_initializer=\"he_normal\", kernel_regularizer=l2(0.00004))(x)\n    x = BatchNormalization(axis=3, momentum=0.9997, scale=False)(x)\n    x = Activation('relu')(x)\n\n    return x\n\n\ndef inception_stem(input):\n    # Define the stem network \n    stem = conv_bn(input, filters=32, kernel_size=(3,3), strides=(2,2), padding='valid')\n    stem = conv_bn(stem, filters=32, kernel_size=(3,3), strides=(1,1), padding='valid')\n    stem = conv_bn(stem, filters=64, kernel_size=(3,3), strides=(1,1))\n\n    branch_11 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(stem)\n    branch_12 = conv_bn(stem, filters=96, kernel_size=(3,3), strides=(2,2), padding='valid')\n    \n    stem = concatenate([branch_11, branch_12], axis=3)\n\n    branch_13 = conv_bn(stem, filters=64, kernel_size=(1,1), strides=(1,1))\n    branch_14 = conv_bn(branch_13, filters=96, kernel_size=(3,3), strides=(1,1), padding='valid')\n    branch_15 = conv_bn(stem, filters=64, kernel_size=(1,1), strides=(1,1))\n    branch_16 = conv_bn(branch_15, filters=64, kernel_size=(1,7), strides=(1,1))\n    branch_17 = conv_bn(branch_16, filters=64, kernel_size=(7,1), strides=(1,1))\n    branch_18 = conv_bn(branch_17, filters=96, kernel_size=(3,3),  strides=(1,1), padding='valid')\n    \n    stem = concatenate([branch_14,branch_18], axis=3)\n\n    branch_19 = conv_bn(stem, filters=192, kernel_size=(3,3), strides=(2,2), padding='valid')\n    branch_20 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(stem)\n    \n    x = concatenate([branch_19,branch_20], axis=3)\n  \n    return x\n\n\ndef inception_a(input):\n\n    branch_11 = conv_bn(input, filters=96, kernel_size=(1,1), strides=(1,1))\n\n    branch_12 = conv_bn(input, filters=64, kernel_size=(1,1), strides=(1,1) )\n    branch_22 = conv_bn(branch_12, filters=96, kernel_size=(3,3), strides=(1,1))\n\n    branch_13 = conv_bn(input, filters=64, kernel_size=(1,1), strides=(1,1))\n    branch_23 = conv_bn(branch_13, filters=96, kernel_size=(3,3), strides=(1,1))\n    branch_33 = conv_bn(branch_23, filters=96, kernel_size=(3,3), strides=(1,1))\n\n    branch_14 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n    branch_24 = conv_bn(branch_14, filters=96, kernel_size=(1,1), strides=(1,1))\n\n    x = concatenate([branch_11,branch_22,branch_33,branch_24], axis=3)\n    \n    return x\n\n\ndef reduction_a(input):\n\n    branch_11 = conv_bn(input, filters=384, kernel_size=(3,3), strides=(2,2), padding='valid')\n\n    branch_12 = conv_bn(input, filters=192, kernel_size=(1,1), strides=(1,1))\n    branch_22 = conv_bn(branch_12, filters=224, kernel_size=(3,3), strides=(1,1))\n    branch_32 = conv_bn(branch_22, filters=256, kernel_size=(3,3), strides=(2,2), padding='valid')\n\n    branch_13 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n\n    x = concatenate([branch_11,branch_32,branch_13], axis=3)\n\n    return x\n\n\ndef inception_b(input):\n\n    branch_11 = conv_bn(input, filters=384, kernel_size=(1,1), strides=(1,1))\n\n    branch_12 = conv_bn(input, filters=192, kernel_size=(1,1), strides=(1,1))\n    branch_22 = conv_bn(branch_12, filters=224, kernel_size=(1,7), strides=(1,1))\n    branch_32 = conv_bn(branch_22, filters=256, kernel_size=(7,1), strides=(1,1))\n\n    branch_13 = conv_bn(input, filters=192, kernel_size=(1,1), strides=(1,1))\n    branch_23 = conv_bn(branch_13, filters=192, kernel_size=(7,1), strides=(1,1))\n    branch_33 = conv_bn(branch_23, filters=224, kernel_size=(1,7), strides=(1,1))\n    branch_43 = conv_bn(branch_33, filters=224, kernel_size=(7,1), strides=(1,1))\n    branch_53 = conv_bn(branch_43, filters=256, kernel_size=(1,7), strides=(1,1))\n\n    branch_14 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n    branch_24 = conv_bn(branch_14, filters=128, kernel_size=(1,1), strides=(1,1))\n\n    x = concatenate([branch_11,branch_32,branch_53,branch_24], axis=3)\n\n    return x\n\n\ndef reduction_b(input):\n\n    branch_11 = conv_bn(input, filters=192, kernel_size=(1,1), strides=(1,1))\n    branch_21 = conv_bn(branch_11, filters=192, kernel_size=(3,3), strides=(2,2), padding='valid')\n\n    branch_12 = conv_bn(input, filters=256, kernel_size=(1,1), strides=(1,1))\n    branch_22 = conv_bn(branch_12, filters=256, kernel_size=(1,7), strides=(1,1))\n    branch_32 = conv_bn(branch_22, filters=320, kernel_size=(7,1), strides=(1,1))\n    branch_42 = conv_bn(branch_32, filters=320, kernel_size=(3,3), strides=(2,2), padding='valid')\n\n    branch_13 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n\n    x = concatenate([branch_21,branch_42,branch_13], axis=3)\n\n    return x\n\n\ndef inception_c(input):\n\n    branch_11 = conv_bn(input, filters=256, kernel_size=(1,1), strides=(1,1))\n\n    branch_12 = conv_bn(input, filters=384, kernel_size=(1,1), strides=(1,1))\n    branch_22 = conv_bn(branch_12, filters=256, kernel_size=(1,3), strides=(1,1))\n    branch_23 = conv_bn(branch_12, filters=256, kernel_size=(3,1), strides=(1,1))\n    branch_33 = concatenate([branch_22,branch_23], axis=3)\n\n    branch_14 = conv_bn(input, filters=384, kernel_size=(1,1), strides=(1,1))\n    branch_24 = conv_bn(branch_14, filters=448, kernel_size=(3,1), strides=(1,1))\n    branch_34 = conv_bn(branch_24, filters=512, kernel_size=(1,3), strides=(1,1))\n    branch_44 = conv_bn(branch_34, filters=256, kernel_size=(1,3), strides=(1,1))\n    branch_45 = conv_bn(branch_34, filters=256, kernel_size=(3,1), strides=(1,1))\n    branch_55 = concatenate([branch_44,branch_45], axis=3)\n\n    branch_16 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n    branch_26 = conv_bn(branch_16, filters=256, kernel_size=(1,1), strides=(1,1))\n\n    x = concatenate([branch_11,branch_33,branch_55,branch_26], axis=3)\n\n    return x\n\n\ndef inception_v4(input_shape, num_classes, include_top):\n    # Build the abstract Inception v4 network\n    '''\n    Args:\n        input_shape: three dimensions in the TensorFlow Data Format\n        num_classes: number of classes\n        weights: pre-defined Inception v4 weights \n        include_top: a boolean, for full traning or finetune \n    Return: \n        logits: the logit outputs of the model.\n    '''\n    inputs = Input(shape=input_shape)\n\n    # Make the the stem of Inception v4 \n    x = inception_stem(inputs)\n\n    # 4 x Inception-A blocks: 35 x 35 x 384\n    for i in range(0, 4):\n        x = inception_a(x)\n\n    # Reduction-A block: # 35 x 35 x 384\n    x = reduction_a(x)\n\n    # 7 x Inception-B blocks: 17 x 17 x 1024\n    for i in range(0, 7):\n        x = inception_b(x)\n\n    # Reduction-B block: 17 x 17 x 1024\n    x = reduction_b(x)\n\n    # 3 x Inception-C blocks: 8 x 8 x 1536\n    for i in range(0, 3):\n        x = inception_c(x)\n\n    # Final pooling and prediction\n    if include_top:\n        # 1 x 1 x 1536\n        x = AveragePooling2D((8,8), padding='valid')(x)\n        x = Dropout(0.5)(x)\n        x = Flatten()(x)\n        x = Dense(units=num_classes, activation=None)(x)\n\n    model = Model(inputs, x, name='inception_v4')\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:58:49.567487Z","iopub.execute_input":"2022-05-29T18:58:49.567754Z","iopub.status.idle":"2022-05-29T18:58:49.612712Z","shell.execute_reply.started":"2022-05-29T18:58:49.567724Z","shell.execute_reply":"2022-05-29T18:58:49.611927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inception_V4","metadata":{}},{"cell_type":"code","source":"input_shape = (299,299,3)\nnum_classes = 1000\ninclude_top = True \n\nmodel = inception_v4(input_shape, num_classes, include_top)\n    \nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(),\n    metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:58:55.469277Z","iopub.execute_input":"2022-05-29T18:58:55.469798Z","iopub.status.idle":"2022-05-29T18:58:58.149873Z","shell.execute_reply.started":"2022-05-29T18:58:55.469742Z","shell.execute_reply":"2022-05-29T18:58:58.145117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = 'best_ImageNet_V4.h5'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='\"val_sparse_top_k_categorical_accuracy\"',\n    mode='max',\n    save_best_only=True)\nmodel.fit(ds_train, validation_data=ds_val, verbose=1, epochs=200, callbacks=[model_checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2022-05-29T18:59:05.521405Z","iopub.execute_input":"2022-05-29T18:59:05.522161Z","iopub.status.idle":"2022-05-30T02:03:49.591071Z","shell.execute_reply.started":"2022-05-29T18:59:05.52212Z","shell.execute_reply":"2022-05-30T02:03:49.589634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(ds_val, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T02:03:53.710504Z","iopub.execute_input":"2022-05-30T02:03:53.711261Z","iopub.status.idle":"2022-05-30T02:04:13.301396Z","shell.execute_reply.started":"2022-05-30T02:03:53.711221Z","shell.execute_reply":"2022-05-30T02:04:13.300683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras-flops\nfrom keras_flops import get_flops\nflops = get_flops(model, batch_size=1)\nprint(f\"FLOPS: {flops / 10 ** 9:.03} G\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nModel_Name = \"InceptionV4_50ep_24_6GF\"\nos.environ[\"MODELNAME\"] = Model_Name\nos.environ[\"MODELNAMEZIP\"] = Model_Name + \".zip\"\nmodel.save(\"./\" + Model_Name)\n!zip -r ./$MODELNAMEZIP ./$MODELNAME\n!rm -rf ./$MODELNAME","metadata":{"execution":{"iopub.status.busy":"2022-05-30T02:06:11.977928Z","iopub.execute_input":"2022-05-30T02:06:11.978237Z","iopub.status.idle":"2022-05-30T02:07:51.507143Z","shell.execute_reply.started":"2022-05-30T02:06:11.978202Z","shell.execute_reply":"2022-05-30T02:07:51.506086Z"},"trusted":true},"execution_count":null,"outputs":[]}]}